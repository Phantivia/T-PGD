{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Metrics\n",
    "gpt = Metrics.GPT2LM(cuda=1)\n",
    "grammarchecker = Metrics.GrammarChecker()\n",
    "use = Metrics.USE(1)\n",
    "edit = Metrics.EditDistance()\n",
    "edit_normalized = Metrics.EditDistance(normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = [k for n,j,k in os.walk('newFinal')][0]\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def read_log(path):\n",
    "    ori, adv = [], []\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('ORI: '):\n",
    "                ori.append(line[5:])\n",
    "            elif line.startswith(\"ADV: \"):\n",
    "                adv.append(line[5:])\n",
    "    print(f\"ORI{len(ori)}, ADV{len(adv)}\")\n",
    "    return ori, adv\n",
    "\n",
    "def eval_PPL(oris,advs, metric, uses=None, limit=0.0):\n",
    "    print(\"Eval with\" + str(metric))\n",
    "    ori_PPLs = []\n",
    "    adv_PPLs = []\n",
    "    delta_PPLs = []\n",
    "    length = len(oris)\n",
    "    for i in tqdm(range(length)):\n",
    "        if uses is not None and uses[i] < limit: continue\n",
    "        ori, adv = oris[i], advs[i]\n",
    "        ori_PPL = metric(ori)\n",
    "        adv_PPL = metric(adv)\n",
    "        delta_PPL = (adv_PPL - ori_PPL)\n",
    "        \n",
    "        ori_PPLs.append(ori_PPL)\n",
    "        adv_PPLs.append(adv_PPL)\n",
    "        delta_PPLs.append(delta_PPL)\n",
    "    def mean(L):\n",
    "        return sum(L)/ len(L)\n",
    "    return  {\n",
    "        'ori': mean(ori_PPLs), \n",
    "        'adv': mean(adv_PPLs), \n",
    "        'delta': mean(delta_PPLs), \n",
    "        'delta%': str(mean(delta_PPLs) / mean(ori_PPLs) * 100)[:7] + '%',\n",
    "        }\n",
    "\n",
    "def eval_score(oris, advs, metric):\n",
    "    print(\"Eval with\" + str(metric))\n",
    "    scores = []\n",
    "    length = len(oris)\n",
    "    for i in tqdm(range(length)):\n",
    "        ori, adv = oris[i], advs[i]\n",
    "        score = metric(ori, adv)\n",
    "        scores.append(score)\n",
    "    def mean(L):\n",
    "        return sum(L)/ len(L)\n",
    "    return mean(scores), scores\n",
    "\n",
    "def dict_putout(d):\n",
    "    _d = {}\n",
    "    for key in d.keys():\n",
    "        if type(d[key]) != type({}):\n",
    "            _d[key] = d[key]\n",
    "        else:\n",
    "            output_d = dict_putout(d[key])\n",
    "            for _key in output_d.keys():\n",
    "                _d[key + '_' + _key] = output_d[_key]\n",
    "    return _d.copy()\n",
    "\n",
    "eval_datas = {}\n",
    "filenames = [\n",
    "             '/home/phantivia/lab/PandRlib/SST2Exp/100-BertOnAlbert-SST2-Layer10-Adv5-Dw0.5-USE-FULL.out',\n",
    "             '/home/phantivia/lab/PandRlib/SST2Exp/100-BertOnBert-SST2-Layer10-Adv5-Dw0.5-USE-FULL.out',\n",
    "             '/home/phantivia/lab/PandRlib/SST2Exp/100-BertOnRoberta-SST2-Layer10-Adv5-Dw0.5-USE-FULL.out']\n",
    "filenames = [\n",
    "           '/home/phantivia/lab/PandRlib/SST2Exp/100-BertOnRoberta-SST2-Layer10-Adv5-Dw0.5-USE-FULL.out',\n",
    "]\n",
    "\n",
    "for file in filenames:\n",
    "    if  'USE' in file:\n",
    "        ori, adv = read_log(file)\n",
    "        eval_datas[file] = {}\n",
    "        \n",
    "        eval_datas[file]['GrammarError'] = eval_PPL(ori, adv, grammarchecker)\n",
    "        eval_datas[file]['USE'], uses = eval_score(ori, adv, use)\n",
    "        eval_datas[file]['PPL'] = eval_PPL(ori, adv, gpt, uses, 0.7)\n",
    "        eval_datas[file]['edit_distance'], _ = eval_score(ori, adv, edit)\n",
    "        eval_datas[file]['edit_distance_normalized'], _ = eval_score(ori, adv, edit_normalized)\n",
    "        \n",
    "        eval_datas[file] = dict_putout(eval_datas[file])\n",
    "        print(file, eval_datas[file])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "luses = [i for i in uses if i < 0.7]\n",
    "len(luses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruses = [i for i in uses if i >= 0.7]\n",
    "sum(ruses) / len(ruses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR = (0.95 - (0.01 * 100 + len(luses))/100)/0.95\n",
    "ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = []\n",
    "for key in eval_datas.keys():\n",
    "    units.append({\n",
    "        'name':key,\n",
    "        **eval_datas[key],\n",
    "    })\n",
    "import pandas\n",
    "df = pandas.DataFrame(units)\n",
    "df.to_csv('eval_result_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanf import scanf\n",
    "pattern = 'BertOn%s-%s-Layer%s'\n",
    "\n",
    "def s(d):\n",
    "    a, b = scanf(pattern, d)\n",
    "    return a, b\n",
    "df = df.sort_values(by = ['victim', 'task'])\n",
    "df = df[['victim', 'task','PPL_ori', 'PPL_adv', 'PPL_delta',\n",
    "       'PPL_delta%', 'GrammarError_ori', 'GrammarError_adv',\n",
    "       'GrammarError_delta', 'GrammarError_delta%', 'USE', 'edit_distance',\n",
    "       'edit_distance_normalized']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = [k for n,j,k in os.walk('newFinal')][0]\n",
    "print(filenames)\n",
    "from scanf import scanf\n",
    "pattern = 'BertOn%s-%s-Layer%s'\n",
    "pattern0 = 'ASR=%f,BS=%f, %s'\n",
    "pattern1 = '%sNUM_WORD_CHANGES=%f'\n",
    "pattern2 = 'Query=%f, Bpsteps=%f, NumberEvalAttacks=%d, AverageStepInSeg=%f'\n",
    "\n",
    "def get_rest(path):\n",
    "    d = {}\n",
    "    d['victim'], d['task'], _ = scanf(pattern, path)\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            args0 = scanf(pattern0, line)\n",
    "            if args0 is not None:\n",
    "                d['ASR'], d['BS'], _ = args0\n",
    "                \n",
    "            args1 = scanf(pattern1, line)\n",
    "            if args1 is not None:\n",
    "                _, d['NUM_WORD_CHANGES'] = args1\n",
    "                \n",
    "            args2 = scanf(pattern2, line)\n",
    "            if args2 is not None:\n",
    "                d['Query'], d['Bpsteps'], d['NumberEvalAttacks'], d['AverageStepInSeg'] = args2\n",
    "    return d\n",
    "\n",
    "datas = []\n",
    "for file in filenames:\n",
    "    if 'USE' in file:\n",
    "        datas.append(get_rest('newFinal/' + file))\n",
    "import pandas\n",
    "rest_df = pandas.DataFrame(datas)\n",
    "rest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_df = rest_df.sort_values(by = ['victim', 'task'])\n",
    "rest_df.to_csv('rest.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28ab90c9d1ffadb26c826c1c6aea2497958474ae3f9654557b40ba40f3526d30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('phantivia': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
