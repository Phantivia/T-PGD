{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_log(path):\n",
    "    ori, adv = [], []\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith('ORI: '):\n",
    "                ori.append(line[5:-1])\n",
    "            elif line.startswith(\"ADV: \"):\n",
    "                adv.append(line[5:-1])\n",
    "    print(path)\n",
    "    print(f\"ORI{len(ori)}, ADV{len(adv)}\")\n",
    "    return ori, adv\n",
    "\n",
    "def collect(paths):\n",
    "    ori, adv = [], []\n",
    "    for path in paths:\n",
    "        _o, _a = read_log(path)\n",
    "        ori += _o\n",
    "        adv += _a\n",
    "    return ori, adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Metrics\n",
    "use = Metrics.USE(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas\n",
    "ori, adv = collect(['/home/phantivia/lab/PandRlib/advLog/BertOnBert-SST2-Layer10-Adv5-Dw0.5-USE-FULL-515-0.out',\n",
    "                    '/home/phantivia/lab/PandRlib/advLog/BertOnBert-SST2-Layer10-Adv5-Dw0.5-USE-FULL-515-1.out'])\n",
    "\n",
    "units = []\n",
    "ori_datasets = datasets.Dataset.load_from_disk('/home/phantivia/datasets/sst2_train')\n",
    "from tqdm import tqdm\n",
    "i = 0\n",
    "for od in tqdm(ori_datasets):\n",
    "    if i == len(ori): break\n",
    "    _ori_sentence = od['sentence'].lower()\n",
    "    if _ori_sentence == ori[i]:\n",
    "        u = use(ori[i], adv[i])\n",
    "        ori_unit = {\n",
    "            'label':od['label'],\n",
    "            'sentence':od['sentence'],\n",
    "            'use':u,\n",
    "            'type':'ori',\n",
    "        }\n",
    "        adv_unit = {\n",
    "            'label':od['label'],\n",
    "            'sentence':adv[i],\n",
    "            'use':u,\n",
    "            'type':'adv',\n",
    "        }\n",
    "        units.append(ori_unit)\n",
    "        units.append(adv_unit)\n",
    "        i += 1\n",
    "\n",
    "df = pandas.DataFrame(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 114514\n",
    "_bar = 0.9\n",
    "bar = 0.7\n",
    "ori_df = df[df['type'] == 'ori']\n",
    "adv_df = df[df['type'] == 'adv']\n",
    "adv_df = adv_df[adv_df['use'] > bar]\n",
    "adv_df  =adv_df[adv_df['use'] < _bar]\n",
    "udf = pandas.concat([ori_df, adv_df]).sample(frac=1, random_state=seed)\n",
    "print(len(udf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.Dataset.from_pandas(udf[['label', 'sentence']])\n",
    "train_ds.save_to_disk('/home/phantivia/datasets/sst2-adv-bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset,load_metric, load_from_disk\n",
    "\n",
    "task = \"sst2\"\n",
    "num_labels = 2\n",
    "\n",
    "train_dataset = train_ds\n",
    "valid_dataset = load_from_disk('/home/phantivia/datasets/sst2-valid')\n",
    "model_checkpoint = 'bert-base-uncased'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "\n",
    "task_valid_keys = {\n",
    "    \"sst2\":'validation',\n",
    "    'ag_news':'test',\n",
    "    'mnli':'validation_matched',\n",
    "}\n",
    "task_to_keys = {  \n",
    "            \"sst2\": (\"sentence\", None),\n",
    "            \"ag_news\": (\"text\", None),\n",
    "            \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "        }\n",
    "\n",
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)\n",
    "\n",
    "encoded_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "encoded_valid_dataset = valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    predictions, labels = eval_pred[0], eval_pred[-1]\n",
    "    predictions = predictions.argmax(axis = 1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "batch_size = 128\n",
    "args = TrainingArguments(\n",
    "    task,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.05,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    seed = seed,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model, '/home/phantivia/models/bert-base-uncased-adv-90.48-89.9.model')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28ab90c9d1ffadb26c826c1c6aea2497958474ae3f9654557b40ba40f3526d30"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('phantivia': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
